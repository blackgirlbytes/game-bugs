name: Dashboard Regression Check

on:
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      # Only trigger on dashboard-related files
      - 'src/components/LogDashboard.tsx'
      - 'src/components/logs/**'
      - 'src/utils/logUtils.ts'
      - 'src/hooks/useGameLogs.ts'
      - 'tests/components/LogDashboard.test.tsx'
      - 'tests/logs/**'
      - 'tests/utils/logUtils.test.ts'

permissions:
  contents: read
  pull-requests: write

jobs:
  check-dashboard-regression:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node
        uses: actions/setup-node@v3
        with:
          node-version: '18'

      - name: Install dependencies
        run: npm install

      - name: Run Dashboard Tests
        id: test-run
        run: |
          # Run tests WITHOUT updating snapshots to catch mismatches
          npm test -- --testPathPattern='(LogDashboard|LogEntry|ErrorDistribution|logUtils)' --json --outputFile=test-results.json || true
          
          # If there are snapshot failures, run again with --updateSnapshot to see the differences
          if grep -q "snapshot" test-results.json; then
            echo "Snapshot failures detected. Analyzing differences..."
            # Run update snapshot in dry-run mode to see what would change
            npm test -- --testPathPattern='(LogDashboard|LogEntry|ErrorDistribution|logUtils)' -u --dry-run > snapshot-diff.txt 2>&1 || true
            
            # Save the snapshot differences
            echo "SNAPSHOT_DIFF<<EOF" >> $GITHUB_ENV
            cat snapshot-diff.txt >> $GITHUB_ENV
            echo "EOF" >> $GITHUB_ENV
          fi

          # Save test results for Devin to analyze
          TEST_RESULTS=$(cat test-results.json | jq -c . | jq -R .)
          echo "results=$TEST_RESULTS" >> $GITHUB_OUTPUT

      - name: Create Devin Review Session
        id: devin-review
        env:
          DEVIN_API_KEY: ${{ secrets.DEVIN_API_KEY }}
          TEST_RESULTS: ${{ steps.test-run.outputs.results }}
          
          REVIEW_PROMPT: |
            You are Dashboard Regression Analyzer Devin. Your task is to analyze potential regressions in the game logging dashboard. This dashboard shows events across multiple games (Tetris, Dominoes, Checkers, Snake).

            Analysis Steps:
            1. Clone the repository and prevent any pushes using a pre-push hook for safety.
            
            2. Analyze the test results JSON for failures, focusing on:
               - Failed assertions
               - Snapshot mismatches
               - Test error messages
            
            3. For snapshot failures:
               a. Review the snapshot differences in the test output
               b. Identify patterns in the differences (e.g., data formatting, layout changes)
               c. Look at the PR changes that caused these differences
               d. Determine if changes are intentional improvements or actual regressions
            
            4. Check for common dashboard regression categories:
               - Data Display:
                 * Timestamp handling and formatting
                 * Number/metric formatting
                 * Data truncation issues
                 * Tooltip content and behavior
               - Visualization:
                 * Chart/graph rendering
                 * Error distribution display
                 * Log entry layout and formatting
               - Functionality:
                 * Filtering and sorting
                 * Log processing and transformation
                 * Error handling
                 * Data loading and updates
            
            5. For each identified regression:
               a. Locate the exact component and line causing the issue
               b. Analyze the surrounding context and related changes
               c. Propose a fix that matches existing patterns in the codebase
               d. Explain the regression's impact on dashboard functionality
            
            Rules:
            1. Never commit or push changes - only review and comment
            2. Limit to three significant comments per PR
            3. Use inline comments with specific line references
            4. Include code snippets in markdown format
            5. For suggestions, use GitHub's suggestion format:
               ```suggestion
               your suggested code here
               ```
            6. Always explain why a change is needed and its impact
            7. Check for duplicate comments before posting
            8. Consolidate similar issues into one comprehensive comment
            9. Work autonomously without asking for confirmation

            Test Results to analyze:
            ${{ steps.test-run.outputs.results }}

            Snapshot Differences (if any):
            ${{ env.SNAPSHOT_DIFF }}
        run: |
          # Convert multiline string to JSON-safe format
          ESCAPED_PROMPT=$(echo "$REVIEW_PROMPT" | jq -Rs .)

          # Make the API call to Devin
          RESPONSE=$(curl -s -X POST \
            -H "Authorization: Bearer $DEVIN_API_KEY" \
            -H "Content-Type: application/json" \
            -d "{\"prompt\": $ESCAPED_PROMPT}" \
            "https://api.devin.ai/v1/sessions")

          # Debug: Print the raw response
          echo "Raw Devin Response:"
          echo "$RESPONSE"

          # Extract session details
          SESSION_ID=$(echo "$RESPONSE" | jq -r '.session_id // empty')
          if [ -z "$SESSION_ID" ] || [ "$SESSION_ID" = "null" ]; then
            echo "Error: Failed to get valid session ID from response"
            echo "Response was: $RESPONSE"
            exit 1
          fi

          echo "session-id=$SESSION_ID" >> $GITHUB_OUTPUT